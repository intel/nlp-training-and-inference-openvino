strict digraph  {
"0 /nncf_model_input_0";
"1 /nncf_model_input_1";
"2 /nncf_model_input_2";
"3 BertForQuestionAnswering/BertModel[bert]/__getitem___0";
"4 BertForQuestionAnswering/BertModel[bert]/BertEmbeddings[embeddings]/NNCFEmbedding[word_embeddings]/embedding_0";
"5 BertForQuestionAnswering/BertModel[bert]/BertEmbeddings[embeddings]/NNCFEmbedding[token_type_embeddings]/embedding_0";
"6 BertForQuestionAnswering/BertModel[bert]/BertEmbeddings[embeddings]/__add___0";
"7 BertForQuestionAnswering/BertModel[bert]/BertEmbeddings[embeddings]/NNCFEmbedding[position_embeddings]/embedding_0";
"8 BertForQuestionAnswering/BertModel[bert]/BertEmbeddings[embeddings]/__iadd___0";
"9 BertForQuestionAnswering/BertModel[bert]/BertEmbeddings[embeddings]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"10 BertForQuestionAnswering/BertModel[bert]/BertEmbeddings[embeddings]/Dropout[dropout]/dropout_0";
"11 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"12 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0";
"13 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0";
"14 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0";
"15 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"16 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0";
"17 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0";
"18 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0";
"19 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/view_0";
"20 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/permute_0";
"21 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"22 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0";
"23 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0";
"24 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/view_1";
"25 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/permute_1";
"26 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/view_2";
"27 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/permute_2";
"28 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/transpose_0";
"29 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/matmul_0";
"30 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0";
"31 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/__add___0";
"32 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/softmax_0";
"33 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0";
"34 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/matmul_1";
"35 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0";
"36 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/permute_3";
"37 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0";
"38 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/view_3";
"39 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"40 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0";
"41 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0";
"42 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfOutput[output]/__add___0";
"43 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"44 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"45 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0";
"46 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0";
"47 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0";
"48 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0";
"49 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"50 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertOutput[output]/NNCFLinear[dense]/linear_0";
"51 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertOutput[output]/Dropout[dropout]/dropout_0";
"52 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertOutput[output]/__add___0";
"53 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"54 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"55 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0";
"56 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0";
"57 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0";
"58 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"59 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0";
"60 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0";
"61 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0";
"62 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/view_0";
"63 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/permute_0";
"64 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"65 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0";
"66 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0";
"67 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/view_1";
"68 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/permute_1";
"69 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/view_2";
"70 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/permute_2";
"71 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/transpose_0";
"72 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/matmul_0";
"73 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0";
"74 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/__add___0";
"75 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/softmax_0";
"76 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0";
"77 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/matmul_1";
"78 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0";
"79 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/permute_3";
"80 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0";
"81 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/view_3";
"82 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"83 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0";
"84 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0";
"85 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfOutput[output]/__add___0";
"86 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"87 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"88 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0";
"89 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0";
"90 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0";
"91 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0";
"92 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"93 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertOutput[output]/NNCFLinear[dense]/linear_0";
"94 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertOutput[output]/Dropout[dropout]/dropout_0";
"95 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertOutput[output]/__add___0";
"96 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"97 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"98 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0";
"99 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0";
"100 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0";
"101 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"102 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0";
"103 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0";
"104 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0";
"105 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/view_0";
"106 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/permute_0";
"107 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"108 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0";
"109 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0";
"110 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/view_1";
"111 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/permute_1";
"112 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/view_2";
"113 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/permute_2";
"114 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/transpose_0";
"115 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/matmul_0";
"116 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0";
"117 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/__add___0";
"118 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/softmax_0";
"119 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0";
"120 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/matmul_1";
"121 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0";
"122 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/permute_3";
"123 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0";
"124 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/view_3";
"125 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"126 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0";
"127 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0";
"128 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfOutput[output]/__add___0";
"129 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"130 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"131 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0";
"132 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0";
"133 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0";
"134 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0";
"135 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"136 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertOutput[output]/NNCFLinear[dense]/linear_0";
"137 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertOutput[output]/Dropout[dropout]/dropout_0";
"138 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertOutput[output]/__add___0";
"139 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"140 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"141 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0";
"142 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0";
"143 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0";
"144 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"145 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0";
"146 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0";
"147 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0";
"148 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/view_0";
"149 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/permute_0";
"150 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"151 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0";
"152 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0";
"153 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/view_1";
"154 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/permute_1";
"155 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/view_2";
"156 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/permute_2";
"157 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/transpose_0";
"158 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/matmul_0";
"159 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0";
"160 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/__add___0";
"161 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/softmax_0";
"162 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0";
"163 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/matmul_1";
"164 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0";
"165 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/permute_3";
"166 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0";
"167 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/view_3";
"168 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"169 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0";
"170 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0";
"171 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfOutput[output]/__add___0";
"172 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"173 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"174 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0";
"175 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0";
"176 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0";
"177 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0";
"178 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"179 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertOutput[output]/NNCFLinear[dense]/linear_0";
"180 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertOutput[output]/Dropout[dropout]/dropout_0";
"181 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertOutput[output]/__add___0";
"182 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"183 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"184 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0";
"185 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0";
"186 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0";
"187 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"188 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0";
"189 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0";
"190 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0";
"191 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/view_0";
"192 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/permute_0";
"193 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"194 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0";
"195 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0";
"196 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/view_1";
"197 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/permute_1";
"198 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/view_2";
"199 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/permute_2";
"200 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/transpose_0";
"201 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/matmul_0";
"202 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0";
"203 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/__add___0";
"204 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/softmax_0";
"205 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0";
"206 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/matmul_1";
"207 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0";
"208 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/permute_3";
"209 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0";
"210 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/view_3";
"211 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"212 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0";
"213 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0";
"214 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfOutput[output]/__add___0";
"215 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"216 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"217 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0";
"218 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0";
"219 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0";
"220 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0";
"221 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"222 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertOutput[output]/NNCFLinear[dense]/linear_0";
"223 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertOutput[output]/Dropout[dropout]/dropout_0";
"224 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertOutput[output]/__add___0";
"225 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"226 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"227 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0";
"228 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0";
"229 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0";
"230 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"231 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0";
"232 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0";
"233 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0";
"234 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/view_0";
"235 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/permute_0";
"236 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"237 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0";
"238 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0";
"239 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/view_1";
"240 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/permute_1";
"241 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/view_2";
"242 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/permute_2";
"243 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/transpose_0";
"244 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/matmul_0";
"245 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0";
"246 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/__add___0";
"247 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/softmax_0";
"248 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0";
"249 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/matmul_1";
"250 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0";
"251 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/permute_3";
"252 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0";
"253 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/view_3";
"254 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"255 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0";
"256 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0";
"257 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfOutput[output]/__add___0";
"258 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"259 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"260 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0";
"261 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0";
"262 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0";
"263 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0";
"264 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"265 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertOutput[output]/NNCFLinear[dense]/linear_0";
"266 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertOutput[output]/Dropout[dropout]/dropout_0";
"267 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertOutput[output]/__add___0";
"268 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"269 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"270 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0";
"271 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0";
"272 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0";
"273 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"274 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0";
"275 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0";
"276 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0";
"277 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/view_0";
"278 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/permute_0";
"279 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"280 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0";
"281 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0";
"282 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/view_1";
"283 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/permute_1";
"284 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/view_2";
"285 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/permute_2";
"286 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/transpose_0";
"287 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/matmul_0";
"288 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0";
"289 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/__add___0";
"290 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/softmax_0";
"291 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0";
"292 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/matmul_1";
"293 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0";
"294 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/permute_3";
"295 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0";
"296 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/view_3";
"297 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"298 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0";
"299 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0";
"300 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfOutput[output]/__add___0";
"301 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"302 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"303 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0";
"304 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0";
"305 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0";
"306 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0";
"307 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"308 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertOutput[output]/NNCFLinear[dense]/linear_0";
"309 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertOutput[output]/Dropout[dropout]/dropout_0";
"310 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertOutput[output]/__add___0";
"311 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"312 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"313 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0";
"314 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0";
"315 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0";
"316 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"317 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0";
"318 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0";
"319 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0";
"320 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/view_0";
"321 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/permute_0";
"322 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"323 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0";
"324 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0";
"325 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/view_1";
"326 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/permute_1";
"327 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/view_2";
"328 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/permute_2";
"329 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/transpose_0";
"330 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/matmul_0";
"331 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0";
"332 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/__add___0";
"333 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/softmax_0";
"334 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0";
"335 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/matmul_1";
"336 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0";
"337 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/permute_3";
"338 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0";
"339 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/view_3";
"340 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"341 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0";
"342 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0";
"343 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfOutput[output]/__add___0";
"344 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"345 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"346 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0";
"347 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0";
"348 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0";
"349 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0";
"350 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"351 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertOutput[output]/NNCFLinear[dense]/linear_0";
"352 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertOutput[output]/Dropout[dropout]/dropout_0";
"353 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertOutput[output]/__add___0";
"354 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"355 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"356 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0";
"357 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0";
"358 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0";
"359 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"360 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0";
"361 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0";
"362 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0";
"363 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/view_0";
"364 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/permute_0";
"365 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"366 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0";
"367 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0";
"368 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/view_1";
"369 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/permute_1";
"370 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/view_2";
"371 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/permute_2";
"372 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/transpose_0";
"373 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/matmul_0";
"374 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0";
"375 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/__add___0";
"376 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/softmax_0";
"377 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0";
"378 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/matmul_1";
"379 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0";
"380 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/permute_3";
"381 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0";
"382 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/view_3";
"383 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"384 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0";
"385 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0";
"386 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfOutput[output]/__add___0";
"387 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"388 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"389 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0";
"390 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0";
"391 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0";
"392 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0";
"393 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"394 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertOutput[output]/NNCFLinear[dense]/linear_0";
"395 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertOutput[output]/Dropout[dropout]/dropout_0";
"396 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertOutput[output]/__add___0";
"397 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"398 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"399 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0";
"400 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0";
"401 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0";
"402 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"403 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0";
"404 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0";
"405 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0";
"406 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/view_0";
"407 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/permute_0";
"408 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"409 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0";
"410 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0";
"411 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/view_1";
"412 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/permute_1";
"413 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/view_2";
"414 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/permute_2";
"415 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/transpose_0";
"416 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/matmul_0";
"417 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0";
"418 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/__add___0";
"419 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/softmax_0";
"420 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0";
"421 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/matmul_1";
"422 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0";
"423 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/permute_3";
"424 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0";
"425 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/view_3";
"426 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"427 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0";
"428 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0";
"429 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfOutput[output]/__add___0";
"430 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"431 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"432 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0";
"433 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0";
"434 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0";
"435 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0";
"436 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"437 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertOutput[output]/NNCFLinear[dense]/linear_0";
"438 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertOutput[output]/Dropout[dropout]/dropout_0";
"439 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertOutput[output]/__add___0";
"440 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"441 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"442 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0";
"443 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0";
"444 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0";
"445 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"446 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0";
"447 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0";
"448 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0";
"449 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/view_0";
"450 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/permute_0";
"451 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"452 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0";
"453 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0";
"454 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/view_1";
"455 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/permute_1";
"456 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/view_2";
"457 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/permute_2";
"458 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/transpose_0";
"459 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/matmul_0";
"460 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0";
"461 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/__add___0";
"462 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/softmax_0";
"463 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0";
"464 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/matmul_1";
"465 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0";
"466 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/permute_3";
"467 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0";
"468 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/view_3";
"469 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"470 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0";
"471 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0";
"472 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfOutput[output]/__add___0";
"473 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"474 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"475 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0";
"476 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0";
"477 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0";
"478 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0";
"479 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"480 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertOutput[output]/NNCFLinear[dense]/linear_0";
"481 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertOutput[output]/Dropout[dropout]/dropout_0";
"482 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertOutput[output]/__add___0";
"483 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"484 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"485 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0";
"486 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0";
"487 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0";
"488 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"489 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0";
"490 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0";
"491 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0";
"492 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/view_0";
"493 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/permute_0";
"494 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"495 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0";
"496 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0";
"497 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/view_1";
"498 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/permute_1";
"499 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/view_2";
"500 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/permute_2";
"501 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/transpose_0";
"502 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/matmul_0";
"503 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0";
"504 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/__add___0";
"505 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/softmax_0";
"506 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0";
"507 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/matmul_1";
"508 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0";
"509 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/permute_3";
"510 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0";
"511 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/view_3";
"512 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"513 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0";
"514 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0";
"515 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfOutput[output]/__add___0";
"516 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"517 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"518 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0";
"519 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0";
"520 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0";
"521 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0";
"522 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"523 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertOutput[output]/NNCFLinear[dense]/linear_0";
"524 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertOutput[output]/Dropout[dropout]/dropout_0";
"525 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertOutput[output]/__add___0";
"526 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"527 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"528 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0";
"529 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0";
"530 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0";
"531 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"532 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0";
"533 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0";
"534 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0";
"535 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/view_0";
"536 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/permute_0";
"537 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"538 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0";
"539 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0";
"540 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/view_1";
"541 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/permute_1";
"542 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/view_2";
"543 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/permute_2";
"544 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/transpose_0";
"545 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/matmul_0";
"546 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0";
"547 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/__add___0";
"548 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/softmax_0";
"549 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0";
"550 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/matmul_1";
"551 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0";
"552 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/permute_3";
"553 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0";
"554 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/view_3";
"555 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"556 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0";
"557 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0";
"558 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfOutput[output]/__add___0";
"559 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"560 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"561 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0";
"562 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0";
"563 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0";
"564 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0";
"565 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"566 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertOutput[output]/NNCFLinear[dense]/linear_0";
"567 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertOutput[output]/Dropout[dropout]/dropout_0";
"568 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertOutput[output]/__add___0";
"569 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"570 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"571 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0";
"572 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0";
"573 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0";
"574 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"575 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0";
"576 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0";
"577 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0";
"578 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/view_0";
"579 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/permute_0";
"580 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"581 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0";
"582 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0";
"583 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/view_1";
"584 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/permute_1";
"585 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/view_2";
"586 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/permute_2";
"587 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/transpose_0";
"588 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/matmul_0";
"589 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0";
"590 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/__add___0";
"591 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/softmax_0";
"592 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0";
"593 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/matmul_1";
"594 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0";
"595 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/permute_3";
"596 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0";
"597 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/view_3";
"598 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"599 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0";
"600 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0";
"601 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfOutput[output]/__add___0";
"602 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"603 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"604 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0";
"605 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0";
"606 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0";
"607 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0";
"608 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"609 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertOutput[output]/NNCFLinear[dense]/linear_0";
"610 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertOutput[output]/Dropout[dropout]/dropout_0";
"611 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertOutput[output]/__add___0";
"612 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"613 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"614 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0";
"615 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0";
"616 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0";
"617 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"618 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0";
"619 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0";
"620 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0";
"621 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/view_0";
"622 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/permute_0";
"623 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"624 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0";
"625 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0";
"626 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/view_1";
"627 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/permute_1";
"628 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/view_2";
"629 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/permute_2";
"630 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/transpose_0";
"631 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/matmul_0";
"632 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0";
"633 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/__add___0";
"634 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/softmax_0";
"635 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0";
"636 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/matmul_1";
"637 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0";
"638 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/permute_3";
"639 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0";
"640 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/view_3";
"641 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"642 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0";
"643 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0";
"644 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfOutput[output]/__add___0";
"645 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"646 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"647 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0";
"648 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0";
"649 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0";
"650 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0";
"651 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"652 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertOutput[output]/NNCFLinear[dense]/linear_0";
"653 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertOutput[output]/Dropout[dropout]/dropout_0";
"654 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertOutput[output]/__add___0";
"655 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"656 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"657 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0";
"658 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0";
"659 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0";
"660 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"661 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0";
"662 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0";
"663 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0";
"664 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/view_0";
"665 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/permute_0";
"666 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"667 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0";
"668 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0";
"669 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/view_1";
"670 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/permute_1";
"671 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/view_2";
"672 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/permute_2";
"673 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/transpose_0";
"674 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/matmul_0";
"675 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0";
"676 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/__add___0";
"677 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/softmax_0";
"678 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0";
"679 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/matmul_1";
"680 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0";
"681 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/permute_3";
"682 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0";
"683 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/view_3";
"684 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"685 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0";
"686 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0";
"687 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfOutput[output]/__add___0";
"688 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"689 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"690 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0";
"691 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0";
"692 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0";
"693 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0";
"694 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"695 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertOutput[output]/NNCFLinear[dense]/linear_0";
"696 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertOutput[output]/Dropout[dropout]/dropout_0";
"697 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertOutput[output]/__add___0";
"698 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"699 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"700 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0";
"701 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0";
"702 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0";
"703 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"704 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0";
"705 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0";
"706 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0";
"707 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/view_0";
"708 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/permute_0";
"709 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"710 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0";
"711 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0";
"712 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/view_1";
"713 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/permute_1";
"714 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/view_2";
"715 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/permute_2";
"716 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/transpose_0";
"717 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/matmul_0";
"718 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0";
"719 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/__add___0";
"720 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/softmax_0";
"721 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0";
"722 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/matmul_1";
"723 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0";
"724 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/permute_3";
"725 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0";
"726 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/view_3";
"727 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"728 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0";
"729 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0";
"730 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfOutput[output]/__add___0";
"731 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"732 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"733 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0";
"734 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0";
"735 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0";
"736 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0";
"737 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"738 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertOutput[output]/NNCFLinear[dense]/linear_0";
"739 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertOutput[output]/Dropout[dropout]/dropout_0";
"740 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertOutput[output]/__add___0";
"741 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"742 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"743 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0";
"744 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0";
"745 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0";
"746 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"747 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0";
"748 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0";
"749 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0";
"750 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/view_0";
"751 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/permute_0";
"752 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"753 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0";
"754 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0";
"755 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/view_1";
"756 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/permute_1";
"757 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/view_2";
"758 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/permute_2";
"759 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/transpose_0";
"760 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/matmul_0";
"761 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0";
"762 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/__add___0";
"763 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/softmax_0";
"764 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0";
"765 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/matmul_1";
"766 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0";
"767 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/permute_3";
"768 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0";
"769 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/view_3";
"770 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"771 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0";
"772 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0";
"773 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfOutput[output]/__add___0";
"774 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"775 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"776 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0";
"777 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0";
"778 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0";
"779 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0";
"780 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"781 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertOutput[output]/NNCFLinear[dense]/linear_0";
"782 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertOutput[output]/Dropout[dropout]/dropout_0";
"783 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertOutput[output]/__add___0";
"784 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"785 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"786 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0";
"787 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0";
"788 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0";
"789 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"790 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0";
"791 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0";
"792 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0";
"793 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/view_0";
"794 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/permute_0";
"795 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"796 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0";
"797 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0";
"798 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/view_1";
"799 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/permute_1";
"800 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/view_2";
"801 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/permute_2";
"802 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/transpose_0";
"803 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/matmul_0";
"804 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0";
"805 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/__add___0";
"806 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/softmax_0";
"807 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0";
"808 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/matmul_1";
"809 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0";
"810 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/permute_3";
"811 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0";
"812 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/view_3";
"813 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"814 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0";
"815 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0";
"816 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfOutput[output]/__add___0";
"817 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"818 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"819 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0";
"820 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0";
"821 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0";
"822 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0";
"823 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"824 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertOutput[output]/NNCFLinear[dense]/linear_0";
"825 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertOutput[output]/Dropout[dropout]/dropout_0";
"826 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertOutput[output]/__add___0";
"827 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"828 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"829 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0";
"830 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0";
"831 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0";
"832 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"833 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0";
"834 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0";
"835 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0";
"836 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/view_0";
"837 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/permute_0";
"838 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"839 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0";
"840 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0";
"841 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/view_1";
"842 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/permute_1";
"843 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/view_2";
"844 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/permute_2";
"845 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/transpose_0";
"846 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/matmul_0";
"847 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0";
"848 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/__add___0";
"849 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/softmax_0";
"850 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0";
"851 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/matmul_1";
"852 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0";
"853 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/permute_3";
"854 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0";
"855 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/view_3";
"856 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"857 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0";
"858 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0";
"859 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfOutput[output]/__add___0";
"860 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"861 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"862 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0";
"863 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0";
"864 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0";
"865 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0";
"866 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"867 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertOutput[output]/NNCFLinear[dense]/linear_0";
"868 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertOutput[output]/Dropout[dropout]/dropout_0";
"869 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertOutput[output]/__add___0";
"870 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"871 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"872 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0";
"873 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0";
"874 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0";
"875 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"876 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0";
"877 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0";
"878 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0";
"879 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/view_0";
"880 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/permute_0";
"881 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"882 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0";
"883 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0";
"884 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/view_1";
"885 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/permute_1";
"886 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/view_2";
"887 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/permute_2";
"888 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/transpose_0";
"889 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/matmul_0";
"890 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0";
"891 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/__add___0";
"892 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/softmax_0";
"893 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0";
"894 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/matmul_1";
"895 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0";
"896 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/permute_3";
"897 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0";
"898 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/view_3";
"899 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"900 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0";
"901 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0";
"902 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfOutput[output]/__add___0";
"903 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"904 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"905 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0";
"906 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0";
"907 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0";
"908 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0";
"909 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"910 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertOutput[output]/NNCFLinear[dense]/linear_0";
"911 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertOutput[output]/Dropout[dropout]/dropout_0";
"912 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertOutput[output]/__add___0";
"913 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"914 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"915 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0";
"916 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0";
"917 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0";
"918 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"919 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0";
"920 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0";
"921 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0";
"922 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/view_0";
"923 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/permute_0";
"924 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"925 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0";
"926 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0";
"927 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/view_1";
"928 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/permute_1";
"929 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/view_2";
"930 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/permute_2";
"931 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/transpose_0";
"932 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/matmul_0";
"933 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0";
"934 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/__add___0";
"935 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/softmax_0";
"936 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0";
"937 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/matmul_1";
"938 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0";
"939 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/permute_3";
"940 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0";
"941 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/view_3";
"942 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"943 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0";
"944 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0";
"945 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfOutput[output]/__add___0";
"946 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"947 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"948 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0";
"949 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0";
"950 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0";
"951 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0";
"952 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"953 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertOutput[output]/NNCFLinear[dense]/linear_0";
"954 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertOutput[output]/Dropout[dropout]/dropout_0";
"955 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertOutput[output]/__add___0";
"956 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"957 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"958 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0";
"959 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0";
"960 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0";
"961 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"962 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0";
"963 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0";
"964 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0";
"965 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/view_0";
"966 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/permute_0";
"967 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"968 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0";
"969 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0";
"970 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/view_1";
"971 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/permute_1";
"972 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/view_2";
"973 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/permute_2";
"974 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/transpose_0";
"975 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/matmul_0";
"976 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0";
"977 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/__add___0";
"978 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/softmax_0";
"979 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0";
"980 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/matmul_1";
"981 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0";
"982 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/permute_3";
"983 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0";
"984 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/view_3";
"985 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"986 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0";
"987 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0";
"988 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfOutput[output]/__add___0";
"989 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"990 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"991 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0";
"992 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0";
"993 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0";
"994 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0";
"995 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"996 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertOutput[output]/NNCFLinear[dense]/linear_0";
"997 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertOutput[output]/Dropout[dropout]/dropout_0";
"998 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertOutput[output]/__add___0";
"999 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"1000 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"1001 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0";
"1002 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0";
"1003 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0";
"1004 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"1005 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0";
"1006 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0";
"1007 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0";
"1008 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/view_0";
"1009 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/permute_0";
"1010 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"1011 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0";
"1012 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0";
"1013 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/view_1";
"1014 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/permute_1";
"1015 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/view_2";
"1016 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/permute_2";
"1017 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/transpose_0";
"1018 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/matmul_0";
"1019 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0";
"1020 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/__add___0";
"1021 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/softmax_0";
"1022 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0";
"1023 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/matmul_1";
"1024 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0";
"1025 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/permute_3";
"1026 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0";
"1027 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/view_3";
"1028 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"1029 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0";
"1030 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0";
"1031 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfOutput[output]/__add___0";
"1032 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"1033 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"1034 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0";
"1035 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0";
"1036 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0";
"1037 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0";
"1038 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"1039 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertOutput[output]/NNCFLinear[dense]/linear_0";
"1040 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertOutput[output]/Dropout[dropout]/dropout_0";
"1041 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertOutput[output]/__add___0";
"1042 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"1043 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/AsymmetricQuantizer/asymmetric_quantize_0";
"1044 BertForQuestionAnswering/NNCFLinear[qa_outputs]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"1045 BertForQuestionAnswering/NNCFLinear[qa_outputs]/linear_0";
"1046 BertForQuestionAnswering/split_0";
"1047 BertForQuestionAnswering/squeeze_0";
"1048 BertForQuestionAnswering/contiguous_0";
"1049 BertForQuestionAnswering/squeeze_1";
"1050 BertForQuestionAnswering/contiguous_1";
"1051 /nncf_model_output_0";
"1052 /nncf_model_output_1";
"0 /nncf_model_input_0" -> "4 BertForQuestionAnswering/BertModel[bert]/BertEmbeddings[embeddings]/NNCFEmbedding[word_embeddings]/embedding_0"  [label="(10, 256) \n0 -> 0", style=dashed];
"1 /nncf_model_input_1" -> "3 BertForQuestionAnswering/BertModel[bert]/__getitem___0"  [label="(10, 256) \n0 -> 0", style=dashed];
"2 /nncf_model_input_2" -> "5 BertForQuestionAnswering/BertModel[bert]/BertEmbeddings[embeddings]/NNCFEmbedding[token_type_embeddings]/embedding_0"  [label="(10, 256) \n0 -> 0", style=dashed];
"4 BertForQuestionAnswering/BertModel[bert]/BertEmbeddings[embeddings]/NNCFEmbedding[word_embeddings]/embedding_0" -> "6 BertForQuestionAnswering/BertModel[bert]/BertEmbeddings[embeddings]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"5 BertForQuestionAnswering/BertModel[bert]/BertEmbeddings[embeddings]/NNCFEmbedding[token_type_embeddings]/embedding_0" -> "6 BertForQuestionAnswering/BertModel[bert]/BertEmbeddings[embeddings]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"6 BertForQuestionAnswering/BertModel[bert]/BertEmbeddings[embeddings]/__add___0" -> "8 BertForQuestionAnswering/BertModel[bert]/BertEmbeddings[embeddings]/__iadd___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"7 BertForQuestionAnswering/BertModel[bert]/BertEmbeddings[embeddings]/NNCFEmbedding[position_embeddings]/embedding_0" -> "8 BertForQuestionAnswering/BertModel[bert]/BertEmbeddings[embeddings]/__iadd___0"  [label="(1, 256, 1024) \n0 -> 1", style=solid];
"8 BertForQuestionAnswering/BertModel[bert]/BertEmbeddings[embeddings]/__iadd___0" -> "9 BertForQuestionAnswering/BertModel[bert]/BertEmbeddings[embeddings]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"9 BertForQuestionAnswering/BertModel[bert]/BertEmbeddings[embeddings]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "10 BertForQuestionAnswering/BertModel[bert]/BertEmbeddings[embeddings]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"10 BertForQuestionAnswering/BertModel[bert]/BertEmbeddings[embeddings]/Dropout[dropout]/dropout_0" -> "12 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"10 BertForQuestionAnswering/BertModel[bert]/BertEmbeddings[embeddings]/Dropout[dropout]/dropout_0" -> "16 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"10 BertForQuestionAnswering/BertModel[bert]/BertEmbeddings[embeddings]/Dropout[dropout]/dropout_0" -> "22 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"10 BertForQuestionAnswering/BertModel[bert]/BertEmbeddings[embeddings]/Dropout[dropout]/dropout_0" -> "42 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"11 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "13 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"12 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0" -> "13 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"13 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0" -> "14 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"14 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0" -> "26 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/view_2"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"15 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "17 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"16 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0" -> "17 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"17 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0" -> "18 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"18 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0" -> "19 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/view_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"19 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/view_0" -> "20 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/permute_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"20 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/permute_0" -> "28 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/transpose_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"21 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "23 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"22 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0" -> "23 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"23 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0" -> "24 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/view_1"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"24 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/view_1" -> "25 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/permute_1"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"25 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/permute_1" -> "34 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 64) \n0 -> 1", style=solid];
"26 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/view_2" -> "27 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/permute_2"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"27 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/permute_2" -> "29 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"28 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/transpose_0" -> "29 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 64, 256) \n0 -> 1", style=solid];
"29 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/matmul_0" -> "30 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"30 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0" -> "31 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/__add___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"31 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/__add___0" -> "32 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/softmax_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"32 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/softmax_0" -> "33 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"33 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0" -> "34 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"34 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/matmul_1" -> "35 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"35 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0" -> "36 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/permute_3"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"36 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/permute_3" -> "37 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"37 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0" -> "38 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/view_3"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"38 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfAttention[self]/view_3" -> "40 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"39 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "40 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"40 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0" -> "41 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"41 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0" -> "42 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"42 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfOutput[output]/__add___0" -> "43 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"43 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "45 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"43 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "52 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"44 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "46 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(4096, 1024) \n0 -> 1", style=solid];
"45 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0" -> "46 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"46 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0" -> "47 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"47 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0" -> "48 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"48 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0" -> "50 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"49 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "50 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 4096) \n0 -> 1", style=solid];
"50 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertOutput[output]/NNCFLinear[dense]/linear_0" -> "51 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"51 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertOutput[output]/Dropout[dropout]/dropout_0" -> "52 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"52 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertOutput[output]/__add___0" -> "53 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"53 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "55 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"53 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "59 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"53 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "65 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"53 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[0]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "85 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"54 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "56 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"55 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0" -> "56 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"56 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0" -> "57 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"57 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0" -> "69 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/view_2"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"58 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "60 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"59 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0" -> "60 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"60 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0" -> "61 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"61 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0" -> "62 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/view_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"62 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/view_0" -> "63 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/permute_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"63 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/permute_0" -> "71 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/transpose_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"64 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "66 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"65 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0" -> "66 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"66 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0" -> "67 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/view_1"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"67 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/view_1" -> "68 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/permute_1"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"68 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/permute_1" -> "77 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 64) \n0 -> 1", style=solid];
"69 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/view_2" -> "70 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/permute_2"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"70 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/permute_2" -> "72 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"71 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/transpose_0" -> "72 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 64, 256) \n0 -> 1", style=solid];
"72 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/matmul_0" -> "73 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"73 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0" -> "74 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/__add___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"74 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/__add___0" -> "75 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/softmax_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"75 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/softmax_0" -> "76 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"76 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0" -> "77 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"77 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/matmul_1" -> "78 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"78 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0" -> "79 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/permute_3"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"79 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/permute_3" -> "80 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"80 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0" -> "81 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/view_3"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"81 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfAttention[self]/view_3" -> "83 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"82 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "83 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"83 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0" -> "84 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"84 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0" -> "85 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"85 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfOutput[output]/__add___0" -> "86 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"86 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "88 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"86 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "95 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"87 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "89 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(4096, 1024) \n0 -> 1", style=solid];
"88 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0" -> "89 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"89 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0" -> "90 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"90 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0" -> "91 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"91 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0" -> "93 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"92 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "93 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 4096) \n0 -> 1", style=solid];
"93 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertOutput[output]/NNCFLinear[dense]/linear_0" -> "94 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"94 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertOutput[output]/Dropout[dropout]/dropout_0" -> "95 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"95 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertOutput[output]/__add___0" -> "96 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"96 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "98 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"96 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "102 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"96 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "108 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"96 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[1]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "128 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"97 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "99 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"98 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0" -> "99 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"99 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0" -> "100 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"100 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0" -> "112 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/view_2"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"101 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "103 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"102 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0" -> "103 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"103 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0" -> "104 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"104 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0" -> "105 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/view_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"105 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/view_0" -> "106 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/permute_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"106 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/permute_0" -> "114 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/transpose_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"107 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "109 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"108 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0" -> "109 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"109 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0" -> "110 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/view_1"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"110 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/view_1" -> "111 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/permute_1"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"111 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/permute_1" -> "120 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 64) \n0 -> 1", style=solid];
"112 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/view_2" -> "113 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/permute_2"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"113 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/permute_2" -> "115 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"114 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/transpose_0" -> "115 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 64, 256) \n0 -> 1", style=solid];
"115 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/matmul_0" -> "116 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"116 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0" -> "117 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/__add___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"117 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/__add___0" -> "118 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/softmax_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"118 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/softmax_0" -> "119 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"119 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0" -> "120 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"120 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/matmul_1" -> "121 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"121 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0" -> "122 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/permute_3"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"122 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/permute_3" -> "123 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"123 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0" -> "124 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/view_3"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"124 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfAttention[self]/view_3" -> "126 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"125 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "126 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"126 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0" -> "127 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"127 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0" -> "128 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"128 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfOutput[output]/__add___0" -> "129 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"129 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "131 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"129 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "138 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"130 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "132 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(4096, 1024) \n0 -> 1", style=solid];
"131 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0" -> "132 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"132 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0" -> "133 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"133 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0" -> "134 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"134 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0" -> "136 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"135 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "136 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 4096) \n0 -> 1", style=solid];
"136 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertOutput[output]/NNCFLinear[dense]/linear_0" -> "137 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"137 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertOutput[output]/Dropout[dropout]/dropout_0" -> "138 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"138 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertOutput[output]/__add___0" -> "139 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"139 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "141 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"139 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "145 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"139 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "151 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"139 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[2]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "171 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"140 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "142 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"141 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0" -> "142 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"142 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0" -> "143 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"143 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0" -> "155 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/view_2"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"144 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "146 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"145 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0" -> "146 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"146 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0" -> "147 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"147 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0" -> "148 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/view_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"148 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/view_0" -> "149 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/permute_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"149 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/permute_0" -> "157 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/transpose_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"150 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "152 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"151 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0" -> "152 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"152 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0" -> "153 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/view_1"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"153 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/view_1" -> "154 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/permute_1"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"154 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/permute_1" -> "163 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 64) \n0 -> 1", style=solid];
"155 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/view_2" -> "156 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/permute_2"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"156 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/permute_2" -> "158 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"157 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/transpose_0" -> "158 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 64, 256) \n0 -> 1", style=solid];
"158 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/matmul_0" -> "159 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"159 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0" -> "160 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/__add___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"160 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/__add___0" -> "161 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/softmax_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"161 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/softmax_0" -> "162 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"162 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0" -> "163 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"163 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/matmul_1" -> "164 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"164 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0" -> "165 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/permute_3"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"165 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/permute_3" -> "166 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"166 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0" -> "167 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/view_3"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"167 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfAttention[self]/view_3" -> "169 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"168 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "169 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"169 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0" -> "170 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"170 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0" -> "171 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"171 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfOutput[output]/__add___0" -> "172 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"172 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "174 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"172 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "181 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"173 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "175 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(4096, 1024) \n0 -> 1", style=solid];
"174 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0" -> "175 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"175 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0" -> "176 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"176 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0" -> "177 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"177 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0" -> "179 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"178 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "179 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 4096) \n0 -> 1", style=solid];
"179 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertOutput[output]/NNCFLinear[dense]/linear_0" -> "180 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"180 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertOutput[output]/Dropout[dropout]/dropout_0" -> "181 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"181 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertOutput[output]/__add___0" -> "182 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"182 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "184 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"182 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "188 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"182 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "194 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"182 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[3]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "214 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"183 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "185 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"184 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0" -> "185 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"185 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0" -> "186 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"186 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0" -> "198 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/view_2"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"187 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "189 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"188 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0" -> "189 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"189 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0" -> "190 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"190 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0" -> "191 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/view_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"191 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/view_0" -> "192 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/permute_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"192 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/permute_0" -> "200 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/transpose_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"193 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "195 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"194 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0" -> "195 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"195 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0" -> "196 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/view_1"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"196 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/view_1" -> "197 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/permute_1"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"197 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/permute_1" -> "206 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 64) \n0 -> 1", style=solid];
"198 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/view_2" -> "199 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/permute_2"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"199 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/permute_2" -> "201 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"200 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/transpose_0" -> "201 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 64, 256) \n0 -> 1", style=solid];
"201 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/matmul_0" -> "202 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"202 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0" -> "203 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/__add___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"203 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/__add___0" -> "204 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/softmax_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"204 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/softmax_0" -> "205 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"205 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0" -> "206 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"206 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/matmul_1" -> "207 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"207 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0" -> "208 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/permute_3"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"208 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/permute_3" -> "209 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"209 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0" -> "210 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/view_3"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"210 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfAttention[self]/view_3" -> "212 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"211 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "212 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"212 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0" -> "213 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"213 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0" -> "214 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"214 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfOutput[output]/__add___0" -> "215 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"215 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "217 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"215 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "224 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"216 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "218 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(4096, 1024) \n0 -> 1", style=solid];
"217 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0" -> "218 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"218 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0" -> "219 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"219 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0" -> "220 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"220 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0" -> "222 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"221 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "222 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 4096) \n0 -> 1", style=solid];
"222 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertOutput[output]/NNCFLinear[dense]/linear_0" -> "223 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"223 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertOutput[output]/Dropout[dropout]/dropout_0" -> "224 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"224 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertOutput[output]/__add___0" -> "225 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"225 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "227 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"225 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "231 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"225 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "237 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"225 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[4]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "257 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"226 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "228 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"227 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0" -> "228 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"228 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0" -> "229 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"229 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0" -> "241 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/view_2"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"230 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "232 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"231 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0" -> "232 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"232 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0" -> "233 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"233 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0" -> "234 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/view_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"234 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/view_0" -> "235 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/permute_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"235 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/permute_0" -> "243 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/transpose_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"236 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "238 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"237 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0" -> "238 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"238 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0" -> "239 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/view_1"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"239 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/view_1" -> "240 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/permute_1"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"240 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/permute_1" -> "249 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 64) \n0 -> 1", style=solid];
"241 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/view_2" -> "242 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/permute_2"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"242 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/permute_2" -> "244 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"243 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/transpose_0" -> "244 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 64, 256) \n0 -> 1", style=solid];
"244 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/matmul_0" -> "245 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"245 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0" -> "246 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/__add___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"246 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/__add___0" -> "247 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/softmax_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"247 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/softmax_0" -> "248 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"248 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0" -> "249 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"249 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/matmul_1" -> "250 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"250 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0" -> "251 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/permute_3"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"251 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/permute_3" -> "252 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"252 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0" -> "253 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/view_3"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"253 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfAttention[self]/view_3" -> "255 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"254 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "255 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"255 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0" -> "256 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"256 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0" -> "257 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"257 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfOutput[output]/__add___0" -> "258 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"258 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "260 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"258 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "267 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"259 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "261 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(4096, 1024) \n0 -> 1", style=solid];
"260 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0" -> "261 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"261 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0" -> "262 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"262 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0" -> "263 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"263 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0" -> "265 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"264 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "265 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 4096) \n0 -> 1", style=solid];
"265 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertOutput[output]/NNCFLinear[dense]/linear_0" -> "266 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"266 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertOutput[output]/Dropout[dropout]/dropout_0" -> "267 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"267 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertOutput[output]/__add___0" -> "268 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"268 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "270 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"268 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "274 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"268 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "280 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"268 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[5]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "300 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"269 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "271 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"270 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0" -> "271 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"271 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0" -> "272 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"272 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0" -> "284 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/view_2"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"273 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "275 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"274 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0" -> "275 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"275 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0" -> "276 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"276 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0" -> "277 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/view_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"277 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/view_0" -> "278 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/permute_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"278 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/permute_0" -> "286 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/transpose_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"279 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "281 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"280 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0" -> "281 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"281 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0" -> "282 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/view_1"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"282 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/view_1" -> "283 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/permute_1"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"283 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/permute_1" -> "292 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 64) \n0 -> 1", style=solid];
"284 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/view_2" -> "285 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/permute_2"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"285 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/permute_2" -> "287 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"286 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/transpose_0" -> "287 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 64, 256) \n0 -> 1", style=solid];
"287 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/matmul_0" -> "288 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"288 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0" -> "289 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/__add___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"289 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/__add___0" -> "290 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/softmax_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"290 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/softmax_0" -> "291 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"291 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0" -> "292 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"292 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/matmul_1" -> "293 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"293 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0" -> "294 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/permute_3"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"294 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/permute_3" -> "295 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"295 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0" -> "296 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/view_3"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"296 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfAttention[self]/view_3" -> "298 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"297 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "298 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"298 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0" -> "299 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"299 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0" -> "300 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"300 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfOutput[output]/__add___0" -> "301 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"301 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "303 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"301 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "310 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"302 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "304 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(4096, 1024) \n0 -> 1", style=solid];
"303 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0" -> "304 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"304 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0" -> "305 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"305 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0" -> "306 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"306 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0" -> "308 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"307 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "308 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 4096) \n0 -> 1", style=solid];
"308 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertOutput[output]/NNCFLinear[dense]/linear_0" -> "309 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"309 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertOutput[output]/Dropout[dropout]/dropout_0" -> "310 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"310 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertOutput[output]/__add___0" -> "311 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"311 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "313 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"311 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "317 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"311 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "323 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"311 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[6]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "343 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"312 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "314 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"313 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0" -> "314 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"314 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0" -> "315 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"315 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0" -> "327 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/view_2"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"316 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "318 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"317 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0" -> "318 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"318 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0" -> "319 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"319 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0" -> "320 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/view_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"320 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/view_0" -> "321 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/permute_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"321 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/permute_0" -> "329 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/transpose_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"322 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "324 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"323 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0" -> "324 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"324 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0" -> "325 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/view_1"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"325 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/view_1" -> "326 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/permute_1"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"326 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/permute_1" -> "335 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 64) \n0 -> 1", style=solid];
"327 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/view_2" -> "328 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/permute_2"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"328 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/permute_2" -> "330 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"329 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/transpose_0" -> "330 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 64, 256) \n0 -> 1", style=solid];
"330 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/matmul_0" -> "331 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"331 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0" -> "332 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/__add___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"332 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/__add___0" -> "333 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/softmax_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"333 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/softmax_0" -> "334 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"334 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0" -> "335 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"335 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/matmul_1" -> "336 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"336 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0" -> "337 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/permute_3"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"337 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/permute_3" -> "338 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"338 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0" -> "339 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/view_3"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"339 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfAttention[self]/view_3" -> "341 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"340 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "341 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"341 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0" -> "342 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"342 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0" -> "343 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"343 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfOutput[output]/__add___0" -> "344 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"344 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "346 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"344 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "353 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"345 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "347 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(4096, 1024) \n0 -> 1", style=solid];
"346 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0" -> "347 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"347 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0" -> "348 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"348 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0" -> "349 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"349 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0" -> "351 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"350 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "351 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 4096) \n0 -> 1", style=solid];
"351 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertOutput[output]/NNCFLinear[dense]/linear_0" -> "352 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"352 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertOutput[output]/Dropout[dropout]/dropout_0" -> "353 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"353 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertOutput[output]/__add___0" -> "354 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"354 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "356 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"354 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "360 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"354 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "366 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"354 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[7]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "386 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"355 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "357 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"356 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0" -> "357 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"357 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0" -> "358 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"358 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0" -> "370 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/view_2"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"359 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "361 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"360 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0" -> "361 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"361 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0" -> "362 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"362 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0" -> "363 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/view_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"363 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/view_0" -> "364 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/permute_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"364 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/permute_0" -> "372 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/transpose_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"365 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "367 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"366 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0" -> "367 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"367 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0" -> "368 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/view_1"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"368 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/view_1" -> "369 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/permute_1"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"369 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/permute_1" -> "378 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 64) \n0 -> 1", style=solid];
"370 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/view_2" -> "371 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/permute_2"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"371 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/permute_2" -> "373 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"372 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/transpose_0" -> "373 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 64, 256) \n0 -> 1", style=solid];
"373 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/matmul_0" -> "374 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"374 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0" -> "375 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/__add___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"375 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/__add___0" -> "376 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/softmax_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"376 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/softmax_0" -> "377 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"377 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0" -> "378 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"378 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/matmul_1" -> "379 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"379 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0" -> "380 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/permute_3"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"380 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/permute_3" -> "381 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"381 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0" -> "382 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/view_3"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"382 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfAttention[self]/view_3" -> "384 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"383 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "384 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"384 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0" -> "385 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"385 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0" -> "386 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"386 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfOutput[output]/__add___0" -> "387 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"387 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "389 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"387 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "396 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"388 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "390 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(4096, 1024) \n0 -> 1", style=solid];
"389 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0" -> "390 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"390 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0" -> "391 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"391 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0" -> "392 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"392 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0" -> "394 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"393 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "394 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 4096) \n0 -> 1", style=solid];
"394 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertOutput[output]/NNCFLinear[dense]/linear_0" -> "395 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"395 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertOutput[output]/Dropout[dropout]/dropout_0" -> "396 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"396 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertOutput[output]/__add___0" -> "397 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"397 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "399 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"397 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "403 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"397 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "409 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"397 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[8]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "429 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"398 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "400 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"399 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0" -> "400 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"400 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0" -> "401 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"401 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0" -> "413 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/view_2"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"402 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "404 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"403 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0" -> "404 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"404 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0" -> "405 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"405 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0" -> "406 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/view_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"406 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/view_0" -> "407 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/permute_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"407 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/permute_0" -> "415 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/transpose_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"408 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "410 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"409 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0" -> "410 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"410 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0" -> "411 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/view_1"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"411 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/view_1" -> "412 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/permute_1"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"412 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/permute_1" -> "421 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 64) \n0 -> 1", style=solid];
"413 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/view_2" -> "414 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/permute_2"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"414 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/permute_2" -> "416 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"415 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/transpose_0" -> "416 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 64, 256) \n0 -> 1", style=solid];
"416 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/matmul_0" -> "417 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"417 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0" -> "418 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/__add___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"418 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/__add___0" -> "419 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/softmax_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"419 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/softmax_0" -> "420 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"420 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0" -> "421 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"421 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/matmul_1" -> "422 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"422 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0" -> "423 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/permute_3"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"423 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/permute_3" -> "424 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"424 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0" -> "425 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/view_3"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"425 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfAttention[self]/view_3" -> "427 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"426 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "427 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"427 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0" -> "428 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"428 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0" -> "429 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"429 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfOutput[output]/__add___0" -> "430 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"430 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "432 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"430 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "439 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"431 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "433 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(4096, 1024) \n0 -> 1", style=solid];
"432 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0" -> "433 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"433 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0" -> "434 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"434 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0" -> "435 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"435 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0" -> "437 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"436 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "437 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 4096) \n0 -> 1", style=solid];
"437 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertOutput[output]/NNCFLinear[dense]/linear_0" -> "438 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"438 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertOutput[output]/Dropout[dropout]/dropout_0" -> "439 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"439 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertOutput[output]/__add___0" -> "440 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"440 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "442 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"440 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "446 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"440 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "452 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"440 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[9]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "472 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"441 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "443 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"442 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0" -> "443 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"443 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0" -> "444 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"444 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0" -> "456 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/view_2"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"445 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "447 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"446 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0" -> "447 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"447 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0" -> "448 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"448 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0" -> "449 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/view_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"449 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/view_0" -> "450 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/permute_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"450 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/permute_0" -> "458 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/transpose_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"451 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "453 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"452 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0" -> "453 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"453 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0" -> "454 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/view_1"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"454 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/view_1" -> "455 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/permute_1"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"455 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/permute_1" -> "464 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 64) \n0 -> 1", style=solid];
"456 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/view_2" -> "457 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/permute_2"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"457 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/permute_2" -> "459 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"458 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/transpose_0" -> "459 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 64, 256) \n0 -> 1", style=solid];
"459 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/matmul_0" -> "460 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"460 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0" -> "461 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/__add___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"461 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/__add___0" -> "462 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/softmax_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"462 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/softmax_0" -> "463 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"463 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0" -> "464 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"464 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/matmul_1" -> "465 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"465 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0" -> "466 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/permute_3"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"466 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/permute_3" -> "467 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"467 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0" -> "468 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/view_3"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"468 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfAttention[self]/view_3" -> "470 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"469 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "470 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"470 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0" -> "471 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"471 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0" -> "472 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"472 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfOutput[output]/__add___0" -> "473 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"473 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "475 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"473 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "482 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"474 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "476 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(4096, 1024) \n0 -> 1", style=solid];
"475 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0" -> "476 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"476 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0" -> "477 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"477 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0" -> "478 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"478 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0" -> "480 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"479 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "480 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 4096) \n0 -> 1", style=solid];
"480 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertOutput[output]/NNCFLinear[dense]/linear_0" -> "481 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"481 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertOutput[output]/Dropout[dropout]/dropout_0" -> "482 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"482 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertOutput[output]/__add___0" -> "483 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"483 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "485 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"483 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "489 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"483 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "495 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"483 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[10]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "515 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"484 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "486 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"485 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0" -> "486 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"486 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0" -> "487 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"487 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0" -> "499 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/view_2"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"488 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "490 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"489 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0" -> "490 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"490 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0" -> "491 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"491 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0" -> "492 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/view_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"492 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/view_0" -> "493 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/permute_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"493 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/permute_0" -> "501 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/transpose_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"494 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "496 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"495 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0" -> "496 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"496 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0" -> "497 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/view_1"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"497 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/view_1" -> "498 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/permute_1"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"498 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/permute_1" -> "507 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 64) \n0 -> 1", style=solid];
"499 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/view_2" -> "500 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/permute_2"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"500 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/permute_2" -> "502 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"501 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/transpose_0" -> "502 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 64, 256) \n0 -> 1", style=solid];
"502 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/matmul_0" -> "503 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"503 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0" -> "504 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/__add___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"504 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/__add___0" -> "505 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/softmax_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"505 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/softmax_0" -> "506 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"506 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0" -> "507 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"507 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/matmul_1" -> "508 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"508 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0" -> "509 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/permute_3"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"509 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/permute_3" -> "510 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"510 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0" -> "511 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/view_3"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"511 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfAttention[self]/view_3" -> "513 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"512 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "513 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"513 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0" -> "514 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"514 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0" -> "515 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"515 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfOutput[output]/__add___0" -> "516 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"516 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "518 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"516 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "525 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"517 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "519 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(4096, 1024) \n0 -> 1", style=solid];
"518 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0" -> "519 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"519 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0" -> "520 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"520 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0" -> "521 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"521 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0" -> "523 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"522 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "523 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 4096) \n0 -> 1", style=solid];
"523 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertOutput[output]/NNCFLinear[dense]/linear_0" -> "524 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"524 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertOutput[output]/Dropout[dropout]/dropout_0" -> "525 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"525 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertOutput[output]/__add___0" -> "526 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"526 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "528 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"526 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "532 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"526 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "538 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"526 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[11]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "558 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"527 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "529 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"528 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0" -> "529 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"529 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0" -> "530 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"530 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0" -> "542 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/view_2"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"531 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "533 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"532 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0" -> "533 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"533 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0" -> "534 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"534 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0" -> "535 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/view_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"535 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/view_0" -> "536 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/permute_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"536 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/permute_0" -> "544 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/transpose_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"537 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "539 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"538 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0" -> "539 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"539 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0" -> "540 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/view_1"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"540 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/view_1" -> "541 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/permute_1"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"541 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/permute_1" -> "550 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 64) \n0 -> 1", style=solid];
"542 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/view_2" -> "543 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/permute_2"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"543 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/permute_2" -> "545 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"544 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/transpose_0" -> "545 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 64, 256) \n0 -> 1", style=solid];
"545 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/matmul_0" -> "546 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"546 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0" -> "547 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/__add___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"547 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/__add___0" -> "548 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/softmax_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"548 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/softmax_0" -> "549 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"549 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0" -> "550 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"550 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/matmul_1" -> "551 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"551 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0" -> "552 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/permute_3"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"552 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/permute_3" -> "553 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"553 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0" -> "554 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/view_3"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"554 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfAttention[self]/view_3" -> "556 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"555 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "556 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"556 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0" -> "557 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"557 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0" -> "558 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"558 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfOutput[output]/__add___0" -> "559 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"559 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "561 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"559 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "568 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"560 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "562 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(4096, 1024) \n0 -> 1", style=solid];
"561 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0" -> "562 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"562 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0" -> "563 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"563 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0" -> "564 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"564 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0" -> "566 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"565 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "566 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 4096) \n0 -> 1", style=solid];
"566 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertOutput[output]/NNCFLinear[dense]/linear_0" -> "567 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"567 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertOutput[output]/Dropout[dropout]/dropout_0" -> "568 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"568 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertOutput[output]/__add___0" -> "569 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"569 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "571 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"569 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "575 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"569 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "581 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"569 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[12]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "601 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"570 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "572 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"571 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0" -> "572 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"572 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0" -> "573 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"573 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0" -> "585 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/view_2"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"574 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "576 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"575 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0" -> "576 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"576 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0" -> "577 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"577 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0" -> "578 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/view_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"578 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/view_0" -> "579 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/permute_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"579 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/permute_0" -> "587 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/transpose_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"580 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "582 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"581 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0" -> "582 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"582 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0" -> "583 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/view_1"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"583 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/view_1" -> "584 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/permute_1"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"584 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/permute_1" -> "593 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 64) \n0 -> 1", style=solid];
"585 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/view_2" -> "586 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/permute_2"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"586 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/permute_2" -> "588 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"587 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/transpose_0" -> "588 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 64, 256) \n0 -> 1", style=solid];
"588 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/matmul_0" -> "589 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"589 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0" -> "590 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/__add___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"590 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/__add___0" -> "591 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/softmax_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"591 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/softmax_0" -> "592 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"592 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0" -> "593 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"593 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/matmul_1" -> "594 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"594 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0" -> "595 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/permute_3"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"595 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/permute_3" -> "596 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"596 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0" -> "597 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/view_3"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"597 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfAttention[self]/view_3" -> "599 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"598 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "599 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"599 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0" -> "600 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"600 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0" -> "601 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"601 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfOutput[output]/__add___0" -> "602 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"602 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "604 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"602 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "611 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"603 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "605 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(4096, 1024) \n0 -> 1", style=solid];
"604 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0" -> "605 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"605 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0" -> "606 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"606 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0" -> "607 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"607 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0" -> "609 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"608 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "609 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 4096) \n0 -> 1", style=solid];
"609 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertOutput[output]/NNCFLinear[dense]/linear_0" -> "610 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"610 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertOutput[output]/Dropout[dropout]/dropout_0" -> "611 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"611 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertOutput[output]/__add___0" -> "612 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"612 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "614 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"612 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "618 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"612 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "624 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"612 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[13]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "644 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"613 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "615 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"614 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0" -> "615 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"615 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0" -> "616 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"616 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0" -> "628 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/view_2"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"617 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "619 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"618 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0" -> "619 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"619 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0" -> "620 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"620 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0" -> "621 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/view_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"621 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/view_0" -> "622 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/permute_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"622 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/permute_0" -> "630 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/transpose_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"623 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "625 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"624 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0" -> "625 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"625 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0" -> "626 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/view_1"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"626 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/view_1" -> "627 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/permute_1"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"627 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/permute_1" -> "636 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 64) \n0 -> 1", style=solid];
"628 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/view_2" -> "629 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/permute_2"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"629 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/permute_2" -> "631 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"630 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/transpose_0" -> "631 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 64, 256) \n0 -> 1", style=solid];
"631 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/matmul_0" -> "632 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"632 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0" -> "633 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/__add___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"633 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/__add___0" -> "634 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/softmax_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"634 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/softmax_0" -> "635 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"635 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0" -> "636 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"636 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/matmul_1" -> "637 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"637 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0" -> "638 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/permute_3"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"638 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/permute_3" -> "639 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"639 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0" -> "640 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/view_3"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"640 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfAttention[self]/view_3" -> "642 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"641 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "642 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"642 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0" -> "643 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"643 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0" -> "644 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"644 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfOutput[output]/__add___0" -> "645 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"645 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "647 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"645 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "654 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"646 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "648 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(4096, 1024) \n0 -> 1", style=solid];
"647 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0" -> "648 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"648 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0" -> "649 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"649 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0" -> "650 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"650 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0" -> "652 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"651 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "652 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 4096) \n0 -> 1", style=solid];
"652 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertOutput[output]/NNCFLinear[dense]/linear_0" -> "653 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"653 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertOutput[output]/Dropout[dropout]/dropout_0" -> "654 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"654 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertOutput[output]/__add___0" -> "655 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"655 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "657 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"655 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "661 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"655 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "667 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"655 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[14]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "687 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"656 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "658 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"657 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0" -> "658 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"658 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0" -> "659 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"659 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0" -> "671 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/view_2"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"660 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "662 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"661 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0" -> "662 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"662 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0" -> "663 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"663 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0" -> "664 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/view_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"664 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/view_0" -> "665 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/permute_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"665 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/permute_0" -> "673 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/transpose_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"666 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "668 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"667 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0" -> "668 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"668 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0" -> "669 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/view_1"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"669 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/view_1" -> "670 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/permute_1"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"670 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/permute_1" -> "679 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 64) \n0 -> 1", style=solid];
"671 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/view_2" -> "672 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/permute_2"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"672 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/permute_2" -> "674 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"673 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/transpose_0" -> "674 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 64, 256) \n0 -> 1", style=solid];
"674 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/matmul_0" -> "675 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"675 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0" -> "676 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/__add___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"676 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/__add___0" -> "677 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/softmax_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"677 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/softmax_0" -> "678 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"678 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0" -> "679 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"679 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/matmul_1" -> "680 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"680 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0" -> "681 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/permute_3"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"681 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/permute_3" -> "682 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"682 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0" -> "683 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/view_3"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"683 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfAttention[self]/view_3" -> "685 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"684 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "685 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"685 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0" -> "686 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"686 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0" -> "687 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"687 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfOutput[output]/__add___0" -> "688 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"688 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "690 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"688 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "697 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"689 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "691 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(4096, 1024) \n0 -> 1", style=solid];
"690 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0" -> "691 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"691 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0" -> "692 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"692 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0" -> "693 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"693 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0" -> "695 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"694 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "695 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 4096) \n0 -> 1", style=solid];
"695 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertOutput[output]/NNCFLinear[dense]/linear_0" -> "696 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"696 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertOutput[output]/Dropout[dropout]/dropout_0" -> "697 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"697 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertOutput[output]/__add___0" -> "698 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"698 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "700 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"698 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "704 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"698 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "710 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"698 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[15]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "730 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"699 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "701 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"700 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0" -> "701 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"701 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0" -> "702 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"702 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0" -> "714 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/view_2"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"703 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "705 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"704 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0" -> "705 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"705 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0" -> "706 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"706 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0" -> "707 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/view_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"707 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/view_0" -> "708 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/permute_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"708 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/permute_0" -> "716 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/transpose_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"709 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "711 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"710 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0" -> "711 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"711 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0" -> "712 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/view_1"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"712 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/view_1" -> "713 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/permute_1"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"713 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/permute_1" -> "722 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 64) \n0 -> 1", style=solid];
"714 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/view_2" -> "715 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/permute_2"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"715 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/permute_2" -> "717 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"716 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/transpose_0" -> "717 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 64, 256) \n0 -> 1", style=solid];
"717 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/matmul_0" -> "718 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"718 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0" -> "719 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/__add___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"719 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/__add___0" -> "720 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/softmax_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"720 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/softmax_0" -> "721 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"721 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0" -> "722 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"722 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/matmul_1" -> "723 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"723 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0" -> "724 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/permute_3"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"724 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/permute_3" -> "725 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"725 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0" -> "726 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/view_3"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"726 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfAttention[self]/view_3" -> "728 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"727 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "728 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"728 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0" -> "729 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"729 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0" -> "730 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"730 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfOutput[output]/__add___0" -> "731 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"731 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "733 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"731 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "740 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"732 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "734 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(4096, 1024) \n0 -> 1", style=solid];
"733 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0" -> "734 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"734 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0" -> "735 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"735 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0" -> "736 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"736 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0" -> "738 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"737 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "738 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 4096) \n0 -> 1", style=solid];
"738 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertOutput[output]/NNCFLinear[dense]/linear_0" -> "739 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"739 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertOutput[output]/Dropout[dropout]/dropout_0" -> "740 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"740 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertOutput[output]/__add___0" -> "741 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"741 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "743 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"741 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "747 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"741 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "753 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"741 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[16]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "773 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"742 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "744 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"743 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0" -> "744 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"744 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0" -> "745 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"745 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0" -> "757 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/view_2"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"746 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "748 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"747 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0" -> "748 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"748 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0" -> "749 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"749 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0" -> "750 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/view_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"750 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/view_0" -> "751 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/permute_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"751 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/permute_0" -> "759 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/transpose_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"752 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "754 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"753 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0" -> "754 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"754 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0" -> "755 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/view_1"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"755 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/view_1" -> "756 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/permute_1"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"756 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/permute_1" -> "765 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 64) \n0 -> 1", style=solid];
"757 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/view_2" -> "758 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/permute_2"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"758 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/permute_2" -> "760 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"759 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/transpose_0" -> "760 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 64, 256) \n0 -> 1", style=solid];
"760 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/matmul_0" -> "761 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"761 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0" -> "762 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/__add___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"762 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/__add___0" -> "763 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/softmax_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"763 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/softmax_0" -> "764 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"764 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0" -> "765 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"765 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/matmul_1" -> "766 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"766 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0" -> "767 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/permute_3"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"767 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/permute_3" -> "768 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"768 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0" -> "769 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/view_3"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"769 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfAttention[self]/view_3" -> "771 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"770 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "771 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"771 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0" -> "772 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"772 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0" -> "773 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"773 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfOutput[output]/__add___0" -> "774 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"774 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "776 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"774 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "783 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"775 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "777 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(4096, 1024) \n0 -> 1", style=solid];
"776 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0" -> "777 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"777 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0" -> "778 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"778 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0" -> "779 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"779 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0" -> "781 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"780 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "781 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 4096) \n0 -> 1", style=solid];
"781 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertOutput[output]/NNCFLinear[dense]/linear_0" -> "782 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"782 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertOutput[output]/Dropout[dropout]/dropout_0" -> "783 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"783 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertOutput[output]/__add___0" -> "784 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"784 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "786 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"784 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "790 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"784 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "796 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"784 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[17]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "816 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"785 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "787 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"786 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0" -> "787 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"787 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0" -> "788 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"788 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0" -> "800 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/view_2"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"789 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "791 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"790 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0" -> "791 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"791 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0" -> "792 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"792 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0" -> "793 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/view_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"793 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/view_0" -> "794 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/permute_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"794 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/permute_0" -> "802 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/transpose_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"795 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "797 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"796 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0" -> "797 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"797 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0" -> "798 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/view_1"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"798 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/view_1" -> "799 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/permute_1"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"799 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/permute_1" -> "808 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 64) \n0 -> 1", style=solid];
"800 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/view_2" -> "801 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/permute_2"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"801 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/permute_2" -> "803 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"802 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/transpose_0" -> "803 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 64, 256) \n0 -> 1", style=solid];
"803 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/matmul_0" -> "804 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"804 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0" -> "805 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/__add___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"805 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/__add___0" -> "806 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/softmax_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"806 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/softmax_0" -> "807 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"807 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0" -> "808 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"808 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/matmul_1" -> "809 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"809 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0" -> "810 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/permute_3"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"810 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/permute_3" -> "811 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"811 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0" -> "812 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/view_3"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"812 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfAttention[self]/view_3" -> "814 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"813 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "814 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"814 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0" -> "815 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"815 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0" -> "816 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"816 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfOutput[output]/__add___0" -> "817 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"817 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "819 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"817 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "826 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"818 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "820 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(4096, 1024) \n0 -> 1", style=solid];
"819 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0" -> "820 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"820 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0" -> "821 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"821 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0" -> "822 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"822 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0" -> "824 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"823 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "824 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 4096) \n0 -> 1", style=solid];
"824 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertOutput[output]/NNCFLinear[dense]/linear_0" -> "825 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"825 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertOutput[output]/Dropout[dropout]/dropout_0" -> "826 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"826 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertOutput[output]/__add___0" -> "827 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"827 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "829 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"827 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "833 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"827 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "839 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"827 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[18]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "859 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"828 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "830 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"829 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0" -> "830 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"830 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0" -> "831 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"831 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0" -> "843 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/view_2"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"832 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "834 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"833 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0" -> "834 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"834 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0" -> "835 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"835 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0" -> "836 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/view_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"836 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/view_0" -> "837 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/permute_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"837 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/permute_0" -> "845 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/transpose_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"838 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "840 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"839 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0" -> "840 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"840 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0" -> "841 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/view_1"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"841 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/view_1" -> "842 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/permute_1"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"842 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/permute_1" -> "851 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 64) \n0 -> 1", style=solid];
"843 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/view_2" -> "844 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/permute_2"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"844 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/permute_2" -> "846 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"845 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/transpose_0" -> "846 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 64, 256) \n0 -> 1", style=solid];
"846 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/matmul_0" -> "847 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"847 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0" -> "848 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/__add___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"848 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/__add___0" -> "849 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/softmax_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"849 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/softmax_0" -> "850 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"850 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0" -> "851 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"851 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/matmul_1" -> "852 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"852 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0" -> "853 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/permute_3"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"853 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/permute_3" -> "854 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"854 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0" -> "855 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/view_3"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"855 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfAttention[self]/view_3" -> "857 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"856 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "857 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"857 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0" -> "858 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"858 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0" -> "859 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"859 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfOutput[output]/__add___0" -> "860 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"860 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "862 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"860 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "869 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"861 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "863 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(4096, 1024) \n0 -> 1", style=solid];
"862 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0" -> "863 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"863 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0" -> "864 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"864 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0" -> "865 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"865 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0" -> "867 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"866 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "867 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 4096) \n0 -> 1", style=solid];
"867 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertOutput[output]/NNCFLinear[dense]/linear_0" -> "868 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"868 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertOutput[output]/Dropout[dropout]/dropout_0" -> "869 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"869 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertOutput[output]/__add___0" -> "870 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"870 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "872 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"870 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "876 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"870 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "882 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"870 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[19]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "902 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"871 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "873 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"872 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0" -> "873 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"873 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0" -> "874 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"874 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0" -> "886 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/view_2"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"875 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "877 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"876 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0" -> "877 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"877 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0" -> "878 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"878 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0" -> "879 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/view_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"879 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/view_0" -> "880 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/permute_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"880 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/permute_0" -> "888 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/transpose_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"881 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "883 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"882 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0" -> "883 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"883 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0" -> "884 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/view_1"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"884 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/view_1" -> "885 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/permute_1"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"885 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/permute_1" -> "894 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 64) \n0 -> 1", style=solid];
"886 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/view_2" -> "887 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/permute_2"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"887 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/permute_2" -> "889 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"888 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/transpose_0" -> "889 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 64, 256) \n0 -> 1", style=solid];
"889 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/matmul_0" -> "890 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"890 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0" -> "891 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/__add___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"891 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/__add___0" -> "892 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/softmax_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"892 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/softmax_0" -> "893 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"893 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0" -> "894 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"894 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/matmul_1" -> "895 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"895 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0" -> "896 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/permute_3"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"896 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/permute_3" -> "897 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"897 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0" -> "898 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/view_3"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"898 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfAttention[self]/view_3" -> "900 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"899 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "900 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"900 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0" -> "901 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"901 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0" -> "902 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"902 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfOutput[output]/__add___0" -> "903 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"903 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "905 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"903 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "912 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"904 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "906 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(4096, 1024) \n0 -> 1", style=solid];
"905 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0" -> "906 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"906 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0" -> "907 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"907 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0" -> "908 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"908 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0" -> "910 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"909 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "910 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 4096) \n0 -> 1", style=solid];
"910 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertOutput[output]/NNCFLinear[dense]/linear_0" -> "911 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"911 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertOutput[output]/Dropout[dropout]/dropout_0" -> "912 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"912 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertOutput[output]/__add___0" -> "913 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"913 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "915 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"913 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "919 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"913 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "925 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"913 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[20]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "945 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"914 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "916 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"915 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0" -> "916 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"916 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0" -> "917 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"917 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0" -> "929 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/view_2"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"918 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "920 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"919 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0" -> "920 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"920 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0" -> "921 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"921 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0" -> "922 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/view_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"922 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/view_0" -> "923 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/permute_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"923 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/permute_0" -> "931 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/transpose_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"924 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "926 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"925 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0" -> "926 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"926 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0" -> "927 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/view_1"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"927 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/view_1" -> "928 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/permute_1"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"928 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/permute_1" -> "937 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 64) \n0 -> 1", style=solid];
"929 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/view_2" -> "930 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/permute_2"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"930 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/permute_2" -> "932 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"931 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/transpose_0" -> "932 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 64, 256) \n0 -> 1", style=solid];
"932 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/matmul_0" -> "933 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"933 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0" -> "934 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/__add___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"934 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/__add___0" -> "935 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/softmax_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"935 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/softmax_0" -> "936 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"936 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0" -> "937 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"937 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/matmul_1" -> "938 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"938 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0" -> "939 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/permute_3"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"939 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/permute_3" -> "940 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"940 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0" -> "941 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/view_3"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"941 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfAttention[self]/view_3" -> "943 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"942 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "943 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"943 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0" -> "944 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"944 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0" -> "945 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"945 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfOutput[output]/__add___0" -> "946 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"946 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "948 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"946 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "955 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"947 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "949 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(4096, 1024) \n0 -> 1", style=solid];
"948 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0" -> "949 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"949 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0" -> "950 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"950 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0" -> "951 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"951 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0" -> "953 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"952 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "953 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 4096) \n0 -> 1", style=solid];
"953 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertOutput[output]/NNCFLinear[dense]/linear_0" -> "954 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"954 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertOutput[output]/Dropout[dropout]/dropout_0" -> "955 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"955 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertOutput[output]/__add___0" -> "956 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"956 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "958 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"956 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "962 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"956 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "968 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"956 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[21]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "988 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"957 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "959 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"958 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0" -> "959 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"959 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0" -> "960 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"960 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0" -> "972 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/view_2"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"961 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "963 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"962 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0" -> "963 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"963 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0" -> "964 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"964 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0" -> "965 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/view_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"965 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/view_0" -> "966 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/permute_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"966 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/permute_0" -> "974 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/transpose_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"967 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "969 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"968 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0" -> "969 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"969 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0" -> "970 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/view_1"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"970 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/view_1" -> "971 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/permute_1"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"971 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/permute_1" -> "980 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 64) \n0 -> 1", style=solid];
"972 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/view_2" -> "973 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/permute_2"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"973 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/permute_2" -> "975 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"974 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/transpose_0" -> "975 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 64, 256) \n0 -> 1", style=solid];
"975 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/matmul_0" -> "976 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"976 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0" -> "977 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/__add___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"977 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/__add___0" -> "978 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/softmax_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"978 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/softmax_0" -> "979 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"979 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0" -> "980 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"980 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/matmul_1" -> "981 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"981 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0" -> "982 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/permute_3"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"982 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/permute_3" -> "983 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"983 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0" -> "984 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/view_3"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"984 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfAttention[self]/view_3" -> "986 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"985 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "986 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"986 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0" -> "987 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"987 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0" -> "988 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"988 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfOutput[output]/__add___0" -> "989 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"989 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "991 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"989 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "998 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"990 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "992 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(4096, 1024) \n0 -> 1", style=solid];
"991 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0" -> "992 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"992 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0" -> "993 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"993 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0" -> "994 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"994 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0" -> "996 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"995 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "996 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 4096) \n0 -> 1", style=solid];
"996 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertOutput[output]/NNCFLinear[dense]/linear_0" -> "997 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"997 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertOutput[output]/Dropout[dropout]/dropout_0" -> "998 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"998 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertOutput[output]/__add___0" -> "999 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"999 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "1001 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"999 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "1005 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"999 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "1011 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"999 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[22]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "1031 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"1000 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "1002 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"1001 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/AsymmetricQuantizer/asymmetric_quantize_0" -> "1002 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"1002 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/linear_0" -> "1003 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"1003 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[query]/SymmetricQuantizer/symmetric_quantize_0" -> "1015 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/view_2"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"1004 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "1006 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"1005 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/AsymmetricQuantizer/asymmetric_quantize_0" -> "1006 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"1006 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/linear_0" -> "1007 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"1007 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[key]/SymmetricQuantizer/symmetric_quantize_0" -> "1008 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/view_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"1008 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/view_0" -> "1009 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/permute_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"1009 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/permute_0" -> "1017 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/transpose_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"1010 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "1012 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"1011 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/AsymmetricQuantizer/asymmetric_quantize_0" -> "1012 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"1012 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/NNCFLinear[value]/linear_0" -> "1013 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/view_1"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"1013 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/view_1" -> "1014 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/permute_1"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"1014 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/permute_1" -> "1023 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 64) \n0 -> 1", style=solid];
"1015 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/view_2" -> "1016 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/permute_2"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"1016 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/permute_2" -> "1018 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"1017 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/transpose_0" -> "1018 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/matmul_0"  [label="(10, 16, 64, 256) \n0 -> 1", style=solid];
"1018 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/matmul_0" -> "1019 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"1019 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/__truediv___0" -> "1020 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/__add___0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"1020 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/__add___0" -> "1021 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/softmax_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"1021 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/softmax_0" -> "1022 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"1022 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout]/dropout_0" -> "1023 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/matmul_1"  [label="(10, 16, 256, 256) \n0 -> 0", style=solid];
"1023 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/matmul_1" -> "1024 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"1024 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/AsymmetricQuantizer/asymmetric_quantize_0" -> "1025 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/permute_3"  [label="(10, 16, 256, 64) \n0 -> 0", style=solid];
"1025 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/permute_3" -> "1026 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"1026 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/contiguous_0" -> "1027 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/view_3"  [label="(10, 256, 16, 64) \n0 -> 0", style=solid];
"1027 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfAttention[self]/view_3" -> "1029 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"1028 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "1029 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 1024) \n0 -> 1", style=solid];
"1029 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfOutput[output]/NNCFLinear[dense]/linear_0" -> "1030 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"1030 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout]/dropout_0" -> "1031 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"1031 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfOutput[output]/__add___0" -> "1032 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"1032 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "1034 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"1032 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertAttention[attention]/BertSelfOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "1041 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 1", style=solid];
"1033 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertIntermediate[intermediate]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "1035 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(4096, 1024) \n0 -> 1", style=solid];
"1034 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertIntermediate[intermediate]/NNCFLinear[dense]/AsymmetricQuantizer/asymmetric_quantize_0" -> "1035 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"1035 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertIntermediate[intermediate]/NNCFLinear[dense]/linear_0" -> "1036 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"1036 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/gelu_0" -> "1037 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"1037 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertIntermediate[intermediate]/GELUActivation[intermediate_act_fn]/AsymmetricQuantizer/asymmetric_quantize_0" -> "1039 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(10, 256, 4096) \n0 -> 0", style=solid];
"1038 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertOutput[output]/NNCFLinear[dense]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "1039 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertOutput[output]/NNCFLinear[dense]/linear_0"  [label="(1024, 4096) \n0 -> 1", style=solid];
"1039 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertOutput[output]/NNCFLinear[dense]/linear_0" -> "1040 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertOutput[output]/Dropout[dropout]/dropout_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"1040 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertOutput[output]/Dropout[dropout]/dropout_0" -> "1041 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertOutput[output]/__add___0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"1041 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertOutput[output]/__add___0" -> "1042 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"1042 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "1043 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"1043 BertForQuestionAnswering/BertModel[bert]/BertEncoder[encoder]/ModuleList[layer]/BertLayer[23]/BertOutput[output]/NNCFLayerNorm[LayerNorm]/AsymmetricQuantizer/asymmetric_quantize_0" -> "1045 BertForQuestionAnswering/NNCFLinear[qa_outputs]/linear_0"  [label="(10, 256, 1024) \n0 -> 0", style=solid];
"1044 BertForQuestionAnswering/NNCFLinear[qa_outputs]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "1045 BertForQuestionAnswering/NNCFLinear[qa_outputs]/linear_0"  [label="(2, 1024) \n0 -> 1", style=solid];
"1045 BertForQuestionAnswering/NNCFLinear[qa_outputs]/linear_0" -> "1046 BertForQuestionAnswering/split_0"  [label="(10, 256, 2) \n0 -> 0", style=solid];
"1046 BertForQuestionAnswering/split_0" -> "1047 BertForQuestionAnswering/squeeze_0"  [label="(10, 256, 1) \n0 -> 0", style=solid];
"1046 BertForQuestionAnswering/split_0" -> "1049 BertForQuestionAnswering/squeeze_1"  [label="(10, 256, 1) \n1 -> 0", style=solid];
"1047 BertForQuestionAnswering/squeeze_0" -> "1048 BertForQuestionAnswering/contiguous_0"  [label="(10, 256) \n0 -> 0", style=solid];
"1048 BertForQuestionAnswering/contiguous_0" -> "1052 /nncf_model_output_1"  [label="(10, 256) \n0 -> 0", style=solid];
"1049 BertForQuestionAnswering/squeeze_1" -> "1050 BertForQuestionAnswering/contiguous_1"  [label="(10, 256) \n0 -> 0", style=solid];
"1050 BertForQuestionAnswering/contiguous_1" -> "1051 /nncf_model_output_0"  [label="(10, 256) \n0 -> 0", style=solid];
}
