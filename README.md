# Overview 
This repository contains NLP use cases build using Intel's different AI components with a focus on the OpenVINO™ toolkit. Each use case is supported with detailed documentation present in the respective folder.
  
  


  
| Use Case Name   |      Description      |  Folder Name |
|:--------|:-------------|:-----|
| Quantization Aware Training and Inference using OpenVINO™ toolkit |   An End-to-End NLP workflow with Quantization Aware Training using Optimum-intel[NNCF]*, and Inference using Optimum-ORT*, OpenVINO™ Model Server & ONNX Runtime with OpenVINO™ Execution Provider | [question-answering-bert-qat](https://github.com/intel/nlp-training-and-inference-openvino/tree/main/question-answering-bert-qat) |


